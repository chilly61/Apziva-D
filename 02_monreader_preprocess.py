#!/usr/bin/env python3
"""
MonReader - 02_æ•°æ®é¢„å¤„ç†
ä½¿ç”¨HOG + é¢œè‰²ç›´æ–¹å›¾æå–ç‰¹å¾
"""

import json
import numpy as np
import os
from pathlib import Path
from collections import defaultdict
from PIL import Image
from skimage.feature import hog
from skimage import color

# ============ é…ç½® ============
# WSLè·¯å¾„æ ¼å¼
DATA_PATH = Path("C:\\Users\\75346\\Desktop\\Apziva Project D\\images")
OUTPUT_PATH = Path("C:\\Users\\75346\\Desktop\\Apziva Project D\\outputs")
OUTPUT_PATH.mkdir(exist_ok=True)

print("=" * 70)
print("ğŸ”§ 02_æ•°æ®é¢„å¤„ç† (HOG + é¢œè‰²ç›´æ–¹å›¾)")
print("=" * 70)


def extract_hog_features(image_path, target_size=(64, 64)):
    """æå–HOG + é¢œè‰²ç›´æ–¹å›¾ç‰¹å¾ (åŒ¹é…ä¹‹å‰çš„1872ç»´)"""
    try:
        img = Image.open(image_path).convert('RGB').resize(target_size)
        arr = np.array(img, dtype=np.float64) / 255.0

        # HOGç‰¹å¾ (64x64å›¾åƒ, 8x8 cells, 2x2 blocks, 9 orientations)
        # ç‰¹å¾æ•°: 7*7 * 4 * 9 = 1764
        gray = color.rgb2gray(arr)
        hog_feat = hog(gray, orientations=9, pixels_per_cell=(8, 8),
                       cells_per_block=(2, 2), feature_vector=True)

        # é¢œè‰²ç›´æ–¹å›¾ (36 bins x 3 channels = 108)
        color_hist = []
        for i in range(3):
            hist, _ = np.histogram(arr[:, :, i], bins=36, range=(0, 1))
            color_hist.extend(hist / hist.sum())

        # åˆå¹¶ç‰¹å¾: 1764 + 108 = 1872
        features = np.concatenate([hog_feat, color_hist])
        return features
    except Exception as e:
        print(f"Error: {e}")
        return None


def load_segment_features(segment_dict, label):
    """åŠ è½½ç‰‡æ®µç‰¹å¾"""
    X, y = [], []
    total = len(segment_dict)

    for idx, (seg_id, images) in enumerate(segment_dict.items()):
        if (idx + 1) % 10 == 0:
            print(f"  å¤„ç†: {idx+1}/{total}")

        features = []
        for img_path in images:
            feat = extract_hog_features(str(img_path))
            if feat is not None:
                features.append(feat)

        if len(features) > 0:
            # å¹³å‡æ± åŒ–
            X.append(np.mean(features, axis=0))
            y.append(1 if label == "flip" else 0)

    return np.array(X), np.array(y)


def main():
    # æ”¶é›†æ•°æ®
    train_flip_segs, train_notflip_segs = defaultdict(list), defaultdict(list)
    test_flip_segs, test_notflip_segs = defaultdict(list), defaultdict(list)

    for label, segs_dict in [("flip", train_flip_segs), ("notflip", train_notflip_segs)]:
        folder = DATA_PATH / "training" / label
        if folder.exists():
            for f in sorted(folder.glob("*.jpg")):
                seg_id = f.name.split('_')[0]
                segs_dict[seg_id].append(f)

    for label, segs_dict in [("flip", test_flip_segs), ("notflip", test_notflip_segs)]:
        folder = DATA_PATH / "testing" / label
        if folder.exists():
            for f in sorted(folder.glob("*.jpg")):
                seg_id = f.name.split('_')[0]
                segs_dict[seg_id].append(f)

    print(f"\nğŸ“ æ•°æ®ç»Ÿè®¡:")
    print(f"  Training: {len(train_flip_segs)+len(train_notflip_segs)}ä¸ªç‰‡æ®µ")
    print(f"  Testing: {len(test_flip_segs)+len(test_notflip_segs)}ä¸ªç‰‡æ®µ")

    # æå–ç‰¹å¾
    print(f"\nğŸ“‚ æå–Trainingç‰¹å¾...")
    X_train_flip, y_train_flip = load_segment_features(train_flip_segs, "flip")
    X_train_notflip, y_train_notflip = load_segment_features(train_notflip_segs, "notflip")
    X_train = np.vstack([X_train_flip, X_train_notflip])
    y_train = np.concatenate([y_train_flip, y_train_notflip])

    print(f"\nğŸ“‚ æå–Testingç‰¹å¾...")
    X_test_flip, y_test_flip = load_segment_features(test_flip_segs, "flip")
    X_test_notflip, y_test_notflip = load_segment_features(test_notflip_segs, "notflip")
    X_test = np.vstack([X_test_flip, X_test_notflip])
    y_test = np.concatenate([y_test_flip, y_test_notflip])

    print(f"\nğŸ“Š ç‰¹å¾ç»Ÿè®¡:")
    print(f"  ç‰¹å¾ç»´åº¦: {X_train.shape[1]}")
    print(f"  Training: {len(X_train)}ä¸ªç‰‡æ®µ")
    print(f"  Testing: {len(X_test)}ä¸ªç‰‡æ®µ")

    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜ç‰¹å¾æ•°æ®...")
    np.savez(
        OUTPUT_PATH / "02_hog_features.npz",
        X_train=X_train,
        y_train=y_train,
        X_test=X_test,
        y_test=y_test
    )

    split_info = {
        "feature_extractor": "HOG + é¢œè‰²ç›´æ–¹å›¾",
        "feature_dim": int(X_train.shape[1]),
        "split_method": "ä½¿ç”¨åŸå§‹training/testingåˆ’åˆ†",
        "training": {
            "flip_segments": len(X_train_flip),
            "notflip_segments": len(X_train_notflip),
            "total_segments": len(X_train)
        },
        "testing": {
            "flip_segments": len(X_test_flip),
            "notflip_segments": len(X_test_notflip),
            "total_segments": len(X_test)
        }
    }

    with open(OUTPUT_PATH / "02_split_info.json", "w") as f:
        json.dump(split_info, f, indent=2)

    print(f"\nâœ… é¢„å¤„ç†å®Œæˆï¼")
    print(f"  ç‰¹å¾: {X_train.shape[1]}ç»´ HOG + é¢œè‰²ç›´æ–¹å›¾")
    print(f"  ä¿å­˜: {OUTPUT_PATH / '02_hog_features.npz'}")


if __name__ == "__main__":
    main()
