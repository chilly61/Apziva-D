#!/usr/bin/env python3
"""
MonReader - 04_è¯„ä¼°ä¸ç»“æœæ±‡æ€»
"""

import json
from pathlib import Path
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report

# ============ é…ç½® ============
OUTPUT_PATH = Path("/mnt/c/Users/75346/Desktop/Apziva Project D/outputs")

def main():
    print("=" * 70)
    print("ğŸ“Š 04_è¯„ä¼°ä¸ç»“æœæ±‡æ€»")
    print("=" * 70)
    
    # è¯»å–è®­ç»ƒç»“æœ
    with open(OUTPUT_PATH / "03_train_results.json", "r") as f:
        train_results = json.load(f)
    
    # è¯»å–åˆ’åˆ†ä¿¡æ¯
    with open(OUTPUT_PATH / "02_split_info.json", "r") as f:
        split_info = json.load(f)
    
    # è¯»å–EDAç»“æœ
    with open(OUTPUT_PATH / "01_eda_results.json", "r") as f:
        eda_results = json.load(f)
    
    # æ±‡æ€»ç»“æœ
    summary = {
        "project": "MonReader - è§†é¢‘ç‰‡æ®µåˆ†ç±»",
        "date": "2026-02-20",
        
        "dataset": {
            "total_segments": eda_results["flip_segments"] + eda_results["notflip_segments"],
            "total_images": eda_results["total_images"],
            "flip_segments": eda_results["flip_segments"],
            "notflip_segments": eda_results["notflip_segments"],
            "train_segments": split_info["total"]["train_segments"],
            "test_segments": split_info["total"]["test_segments"],
            "train_images": split_info["total"]["train_images"],
            "test_images": split_info["total"]["test_images"]
        },
        
        "data_leakage_check": split_info["data_leakage_check"],
        
        "model": train_results["model"],
        
        "final_results": {
            "accuracy": train_results["results"]["accuracy"],
            "f1_score": train_results["results"]["f1_score"]
        },
        
        "method": train_results["method"],
        
        "conclusion": "ä½¿ç”¨å®Œæ•´ç‰‡æ®µç‰¹å¾è¿›è¡Œåˆ†ç±»ï¼ŒæŒ‰ç‰‡æ®µIDåˆ’åˆ†ç¡®ä¿æ— æ•°æ®æ³„éœ²"
    }
    
    # æ‰“å°æ±‡æ€»
    print(f"\nğŸ“‹ é¡¹ç›®æ±‡æ€»:")
    print(f"  é¡¹ç›®: {summary['project']}")
    print(f"  æ—¥æœŸ: {summary['date']}")
    
    print(f"\nğŸ“ æ•°æ®é›†:")
    print(f"  æ€»ç‰‡æ®µæ•°: {summary['dataset']['total_segments']}")
    print(f"  æ€»å›¾ç‰‡æ•°: {summary['dataset']['total_images']}")
    print(f"  è®­ç»ƒç‰‡æ®µ: {summary['dataset']['train_segments']}")
    print(f"  æµ‹è¯•ç‰‡æ®µ: {summary['dataset']['test_segments']}")
    
    print(f"\nâš ï¸ æ•°æ®æ³„éœ²æ£€æŸ¥:")
    print(f"  Flipé‡å : {summary['data_leakage_check']['flip_overlap']}")
    print(f"  NotFlipé‡å : {summary['data_leakage_check']['notflip_overlap']}")
    print(f"  æ— æ³„éœ²: {summary['data_leakage_check']['no_leakage']}")
    
    print(f"\nğŸ§  æ¨¡å‹:")
    print(f"  ç±»å‹: {summary['model']['type']}")
    print(f"  å‚æ•°: n_estimators={summary['model']['n_estimators']}, max_depth={summary['model']['max_depth']}")
    
    print(f"\nğŸ“Š æœ€ç»ˆç»“æœ:")
    print(f"  Accuracy: {summary['final_results']['accuracy']:.4f}")
    print(f"  F1 Score: {summary['final_results']['f1_score']:.4f}")
    
    print(f"\nğŸ’¡ ç»“è®º:")
    print(f"  {summary['conclusion']}")
    
    # ä¿å­˜æ±‡æ€»
    with open(OUTPUT_PATH / "04_summary.json", "w") as f:
        json.dump(summary, f, indent=2)
    
    print(f"\nâœ… æ±‡æ€»å®Œæˆï¼ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_PATH / '04_summary.json'}")
    
    return summary

if __name__ == "__main__":
    main()
