#!/usr/bin/env python3
"""
MonReader - 02b_CNNé¢„å¤„ç†
ä½¿ç”¨ResNet-50æå–CNNç‰¹å¾
"""

import json
import numpy as np
import os
from pathlib import Path
from collections import defaultdict
from PIL import Image
import time

# å‡å°‘TensorFlowæ—¥å¿—
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# ============ é…ç½® ============
DATA_PATH = Path("yourpath/images")
OUTPUT_PATH = Path("yourpath/outputs")
OUTPUT_PATH.mkdir(exist_ok=True)

print("=" * 70)
print("ğŸ”§ 02b_CNNé¢„å¤„ç† (ResNet-50ç‰¹å¾æå–)")
print("=" * 70)

# åŠ è½½ResNet-50
print("\nğŸ“¥ åŠ è½½ResNet-50æ¨¡å‹...")
start = time.time()
from tensorflow import keras
from keras.applications import ResNet50
from keras.applications.resnet50 import preprocess_input

base_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')
feature_extractor = keras.Model(inputs=base_model.input, outputs=base_model.output)
print(f"âœ… ResNet-50åŠ è½½å®Œæˆ ({time.time()-start:.1f}s)ï¼Œè¾“å‡ºç»´åº¦: 2048")

def extract_cnn_features(image_path, target_size=(224, 224)):
    """ä½¿ç”¨ResNet-50æå–CNNç‰¹å¾"""
    try:
        img = Image.open(image_path).convert('RGB').resize(target_size)
        arr = np.array(img, dtype=np.float32)
        arr = np.expand_dims(arr, axis=0)
        arr = preprocess_input(arr)
        features = feature_extractor.predict(arr, verbose=0)
        return features[0]
    except Exception as e:
        print(f"Error: {e}")
        return None

def load_segment_cnn_features(segment_dict, label):
    """åŠ è½½ç‰‡æ®µçš„CNNç‰¹å¾ - æ¯ä¸ªç‰‡æ®µç”¨å¤šå¸§ç‰¹å¾çš„å¹³å‡"""
    X, y, lengths = [], [], []
    total = len(segment_dict)
    
    for idx, (seg_id, images) in enumerate(segment_dict.items()):
        if (idx + 1) % 10 == 0:
            print(f"  å¤„ç†: {idx+1}/{total}")
        
        features = []
        for img_path in images:
            feat = extract_cnn_features(str(img_path))
            if feat is not None:
                features.append(feat)
        
        if len(features) > 0:
            # æ–¹æ¡ˆ1: å¹³å‡æ± åŒ–
            avg_features = np.mean(features, axis=0)
            X.append(avg_features)
            lengths.append(len(features))
            y.append(1 if label == "flip" else 0)
    
    return X, y, lengths

def main():
    # æ”¶é›†æ•°æ®
    train_flip_segs, train_notflip_segs = defaultdict(list), defaultdict(list)
    test_flip_segs, test_notflip_segs = defaultdict(list), defaultdict(list)
    
    for label, segs_dict in [("flip", train_flip_segs), ("notflip", train_notflip_segs)]:
        folder = DATA_PATH / "training" / label
        if folder.exists():
            for f in sorted(folder.glob("*.jpg")):
                seg_id = f.name.split('_')[0]
                segs_dict[seg_id].append(f)
    
    for label, segs_dict in [("flip", test_flip_segs), ("notflip", test_notflip_segs)]:
        folder = DATA_PATH / "testing" / label
        if folder.exists():
            for f in sorted(folder.glob("*.jpg")):
                seg_id = f.name.split('_')[0]
                segs_dict[seg_id].append(f)
    
    print(f"\nğŸ“ æ•°æ®ç»Ÿè®¡:")
    print(f"  Training: {len(train_flip_segs)+len(train_notflip_segs)}ä¸ªç‰‡æ®µ")
    print(f"  Testing: {len(test_flip_segs)+len(test_notflip_segs)}ä¸ªç‰‡æ®µ")
    
    # æå–ç‰¹å¾
    print(f"\nğŸ“‚ æå–Training CNNç‰¹å¾...")
    X_train_flip, y_train_flip, l_train_flip = load_segment_cnn_features(train_flip_segs, "flip")
    X_train_notflip, y_train_notflip, l_train_notflip = load_segment_cnn_features(train_notflip_segs, "notflip")
    
    print(f"\nğŸ“‚ æå–Testing CNNç‰¹å¾...")
    X_test_flip, y_test_flip, l_test_flip = load_segment_cnn_features(test_flip_segs, "flip")
    X_test_notflip, y_test_notflip, l_test_notflip = load_segment_cnn_features(test_notflip_segs, "notflip")
    
    # åˆå¹¶
    X_train = np.array(X_train_flip + X_train_notflip)
    y_train = np.array(y_train_flip + y_train_notflip)
    X_test = np.array(X_test_flip + X_test_notflip)
    y_test = np.array(y_test_flip + y_test_notflip)
    
    train_seg = len(X_train)
    test_seg = len(X_test)
    
    print(f"\nğŸ“Š ç‰¹å¾ç»Ÿè®¡:")
    print(f"  ç‰¹å¾ç»´åº¦: 2048ç»´/ç‰‡æ®µ (å¹³å‡æ± åŒ–)")
    print(f"  Training: {train_seg}ä¸ªç‰‡æ®µ (Flip: {sum(y_train)}, NotFlip: {len(y_train)-sum(y_train)})")
    print(f"  Testing: {test_seg}ä¸ªç‰‡æ®µ (Flip: {sum(y_test)}, NotFlip: {len(y_test)-sum(y_test)})")
    
    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜ç‰¹å¾æ•°æ®...")
    np.savez(
        OUTPUT_PATH / "02b_cnn_features.npz",
        X_train=X_train,
        y_train=y_train,
        X_test=X_test,
        y_test=y_test
    )
    
    split_info = {
        "feature_extractor": "ResNet-50 (ImageNeté¢„è®­ç»ƒ)",
        "feature_dim": 2048,
        "pooling": "å¹³å‡æ± åŒ– (mean pooling)",
        "split_method": "ä½¿ç”¨åŸå§‹training/testingåˆ’åˆ†",
        "training": {
            "flip_segments": len(X_train_flip),
            "notflip_segments": len(X_train_notflip),
            "total_segments": train_seg
        },
        "testing": {
            "flip_segments": len(X_test_flip),
            "notflip_segments": len(X_test_notflip),
            "total_segments": test_seg
        }
    }
    
    with open(OUTPUT_PATH / "02b_split_info.json", "w") as f:
        json.dump(split_info, f, indent=2)
    
    print(f"\nâœ… CNNé¢„å¤„ç†å®Œæˆï¼")
    print(f"  ç‰¹å¾: 2048ç»´ ResNet-50ç‰¹å¾/ç‰‡æ®µ")
    print(f"  ä¿å­˜: {OUTPUT_PATH / '02b_cnn_features.npz'}")

if __name__ == "__main__":
    main()
